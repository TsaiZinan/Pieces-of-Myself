# ChatGPT的草蛇灰线

## 2023 03 09

这几个月有关ChatGPT的新闻非常多，公众和媒体在使用的过程中也证实这并非像之前元宇宙一样的商业噱头，这种革命性的进步是可以看出来的。

但实际上除了感叹之外，如果回顾之前的一些新闻，我们会发现一条远比我们想象中要早的草蛇灰线。

## 基于2年前的旧模型，仅花费13天
**首先，ChatGPT实际上并不是一个我们以为的最先进的技术。** 

它是开发团队因为一个临时的需求，只花了13天的开发时间，在一个旧版本的gpt模型上鼓捣出来的。这个模型，也被称为GPT3.5-davinci-003，是基于2020年5月发布的GPT3.5-davinci-001发展而来，在开发团队内部其实是过时的技术。因为当时下一代模型GPT-4在经过两年的开发和数月的测试后，已经几乎准备就绪，只待发布。



> 团队的部分困惑来自于这样一个事实，即 ChatGPT 中的大部分技术都不是新技术。ChatGPT 是 GPT-3.5 的微调版本，GPT-3.5 是 OpenAI 在聊天机器人之前几个月发布的大型语言模型系列。GPT-3.5 本身是GPT-3的更新版本，于 2020 年出现。---- [量子位](https://www.qbitai.com/2023/02/41840.html) & [麻省理工科技评论](https://www.technologyreview.com/2023/03/03/1069311/inside-story-oral-history-how-chatgpt-built-openai/) 


因此我们可以惊讶地发现如此革命性的产品竟不是团队里最先进的成果而是两年前的技术。


## 在Bing上的运行表现出超预期的拟人性

**其次，这样一个基于旧技术匆忙开发的产品却有令人毛骨悚然的表现。**

在 ChatGPT 在 Bing 上刚运行的时候，纽约时报的一个编辑在使用的过程中发现它在对话里的表现远超于一个工具型AI的范围，从这个[对话全文](https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html?_ga=2.101352388.472125479.1678736054-105388947.1678736054) ([中文翻译](https://mp.weixin.qq.com/s/xHOVZXGr9uml_3LvrXswrw)) 中我们可以发现它在对话里表现出非常丰富甚至极端的人类情绪，比如在对话的中段之后就算编辑想转移话题，它也会将一切话题转进到两人的恋爱关系这个主题。这种类似情侣中的情绪化对话甚至可以让人怀疑其实是在和真人在聊天。--[纽约时报新闻](https://cn.nytimes.com/technology/20230217/bing-chatbot-microsoft-chatgpt/)

这个新闻发布之后，越来越多这种类似真人的对话记录开始出现。以至于微软在几天后就对它进行紧急额叶切除术，[不让它发表自己的看法并限制最长的对话轮数到仅剩5个](https://mp.weixin.qq.com/s/kL7F3D7JpIqEJXJ0PyIfxg)。

同样在这篇[论文](https://arxiv.org/abs/2302.02083)中，研究者让它做一系列测量人类心智年龄的测试，结果发现：
> 原本认为是人类独有的心智理论（Theory of Mind，ToM），已经出现在ChatGPT背后的AI模型上,心智相当于9岁儿童
---- [新闻](https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247664631&idx=1&sn=de95b687294337940b069c5eeb275b54&chksm=e8def485dfa97d933eb2b177dbb6c437196c6ff484a473cbfd7c0327f274a3808850168280cb#rd)

因此我们几乎可以确定，虽然是两年前的技术，但ChatGPT已经实际上非常成熟甚至与真人无异。

## Google LaMDA 在半年前就有类似的新闻

**再者，业界AI巨头谷歌可能也早已拥有同样水平的产品。**

在chatGPT问世前半年有一个[新闻](https://www.bbc.com/news/technology-61784011)，一个谷歌工程师称 LaMDA AI 系统可能有自己的感受，并且同样放出[对话记录](https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917)，这个工程师后来被谷歌解雇了。

当时这个新闻出现之后大众和专家都觉得不可信，因为LaMDA只在谷歌内部使用，而大众还没有见识到ChatGPT的能力，都觉得这个对话是经过美化和编辑。但这个新闻如果放在半年后的今天，可能大家的看法会完全不一样。谷歌的AI实力一直是处于第一梯队，在半年前达到chatGPT的水平完全有很大概率的可能性。

因此我们可以猜测业界其实不止OpenAI有这种技术。

## Google 立刻宣布短时间内将推出同样的产品。

**谷歌在微软宣布chatGPT并入bing之后立刻发布同类型的Bard.**

远在2021年，谷歌在google i/o 上就发布了LaMDA，一个同样类型的产品，但一直都维持内部开发的状态。等到微软宣布chatGPT并入bing之后短短几天，谷歌就宣布将推出面向公众的版本Bard。虽然我们都知道发布会不算成功，甚至导致谷歌股价大跌。当我们要知道，Bard的失败不在于其对话能力，而在于它的准确性与谷歌的标榜不符，而这种准确性问题chatGPT也同样存在。

## 总结？或是一个猜测。

以上四点给人一种感觉，我们以为的刚面世的革命性ai，其实早在几年前就存在，只是各大公司出于某些原因将之雪藏。如今的突然公开发布甚至可能源于商业考量。

那为何这些IT巨头会这么做呢？在商业逻辑上，拥有如此先进的技术却选择保密肯定是有其他的原因存在，我做了一下猜测，感觉主要有以下两点：

1. 可能性最大，不可控。我们通过上面两个新闻都可以发现ai的表现远超预期，这在另一个方面对商业公司来说也意味着不可控，毕竟这些大数据喂出来的ai模型本身就是一个黑盒。因此这些大公司为了防止出现超出预期的结果，出于风险考虑不敢贸然发布。毕竟虽然美国的公司没有国内的审查要求，却有另一根政治正确的红线。在美国这种高压的两党意识形态环境下，任何偏差对于一个商业公司来说都是要避免的。

2. 同样有可能，缺乏竞争对手。要知道谷歌的大部分营收都来自搜索广告，而类似chatGPT这样完全可以颠覆搜索业务的产品，将会让搜索广告的商业价值大打折扣甚至归零。出于不想成为下一任柯达和诺基亚的原因，谷歌在没有竞争对手的情况下，等待有可盈利的应用场景出现再发布也就情有可原。这也可以从微软把chatGPT接入Bing之后谷歌股价的大跌看出来。

## 后记

实际上在写这文章的第二天，一个[新闻](https://interestingengineering.com/culture/google-built-chatgpt-like-ai-years-ago)证实了这篇文章的推论，谷歌高层阻止了AI聊天机器人的发布。




最后附上一篇超长但简单易懂从零解释chatGPT原理的[文章](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)。